<DOC>
<DOCNO>SK-technology-44-20180221</DOCNO>
<URL>https://www.skynewsarabia.com/web/article/1023744</URL>
<SRC>skynews</SRC>
<CAT>technology</CAT>
<TITLE>خبراء: احذروا كوارث "الذكاء الصناعي" بالعقد المقبل</TITLE>
<TIME>Wed, 21 Feb 2018 07:37:14 GMT</TIME>
<AUTHOR>أبوظبي - سكاي نيوز عربية</AUTHOR>
<ABSTRACT>
حذر خبراء بريطانيون من أن الإرهابيين والمجرمين قد يستغلون التطورات المتسارعة في مجال الذكاء الاصطناعي، لتنفيذ أعمال سرق وقتل وتشويه للسمعة.
</ABSTRACT>
<TEXT>
حذر خبراء بريطانيون من أن الإرهابيين والمجرمين قد يستغلون التطورات المتسارعة في مجال الذكاء الاصطناعي، لتنفيذ أعمال سرق وقتل وتشويه للسمعة.
ووفق ما أوردت صحيفة "تلغراف" البريطانية، الأربعاء، فإن 26 خبيرا من معهد مستقبل البشرية في جامعة أكسفورد ومركز دراسات مخاطر المحتملة من تكنولوجيا المستقبل بجامعة كامبريدج أصدروا تقريرا يستعرض المخاطر الجانبية للذكاء الاصطناعي خصوصا في السيارات الذاتية القيادة.
وقالوا الخبراء إن الاستخدام "الخبيث" للذكاء الاصطناعي سيمثل خطرا واضحا على المجتمع، مرجحين أن يظهر ذلك الخطر خلال العقد المقبل.
وأشاروا إلى أن الإرهابيين قد يستغلوا السيارات الذاتية القيادة في تنفيذ هجمات صدم أو دهس واسعة النطاق.
وحذر التقرير من الثقة الزائدة في السيارات الذاتية القيادة، لافتا إلى دلائل تشير إلى إمكانية التلاعب بها، مثل التحكم في توقف السيارة عند إشارات المرور، أو إطلاق طائرات مسيرة لتنفيذ هجمات في الجو.
ويقول التقرير إن الذكاء الاصطناعي يتطور على نحو غير مسبوق، لكن هناك مخاوف بشأن قدراتها على إلحاق الضرر، لا سيما مع احتمال أن يستغل الإرهابيون هذه التطورات لغاياتهم.
وأضاف التقرير أن الذكاء الاصطناعي سيغير شكل المخاطر التي يتعرض لها الأشخاص والمؤسسات والدول، إذ يمكن للمجرمين تجهيز أدوات لسرقة المعلومات وإلحاق الضرر بالخصوصية.
وقال إن بوسع قراصنة الإنترنت و"الدول المارقة" توظيف الذكاء الاصطناعي في التدخل في الانتخابات بواسطة الجيوش الالكترونية من خلال روبوتات ونشر أخبار مزيفة لتوجيه النقاشات في شبكات التواصل.
 وذكر أن الذكاء الاصطناعي يسهل من عملية فبركة الفيديوهات والأصوات، وهو أمر قد يستخدم في تشويه سمعة السياسيين والمشاهير.
ومن المقرر أن يقدم الخبراء تقريرهم إلى الحكومات والشركات التقنية، وعبروا عن أملهم في أن يؤدي ذلك إلى وضع إرشادات تحدد كيفية التطوير الآمن للذكاء الاصطناعي.
</TEXT>
</DOC>
